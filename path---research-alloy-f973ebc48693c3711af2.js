webpackJsonp([0xc1fad8499ce7],{876:function(e,t){e.exports={data:{markdownRemark:{htmlAst:{type:"root",children:[{type:"element",tagName:"h3",properties:{id:"abstract"},children:[{type:"element",tagName:"a",properties:{href:"#abstract",ariaHidden:!0,className:["anchor"]},children:[{type:"element",tagName:"svg",properties:{ariaHidden:"true",height:16,version:"1.1",viewBox:"0 0 16 16",width:16},children:[{type:"element",tagName:"path",properties:{fillRule:"evenodd",d:"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"},children:[]}]}]},{type:"text",value:"Abstract"}]},{type:"text",value:"\n"},{type:"element",tagName:"p",properties:{},children:[{type:"text",value:"Crowdsourced clustering approaches present a promising way to harness deep semantic knowledge for clustering complex information. However, existing approaches have difficulties supporting the global context needed for workers to generate meaningful categories, and are costly because all items require human judgments. We introduce Alloy, a hybrid approach that combines the richness of human judgments with the power of machine algorithms. Alloy supports greater global context through a new sample and search crowd pattern which changes the crowd’s task from classifying a fixed subset of items to actively sampling and querying the entire dataset. It also improves efficiency through a two phase process in which crowds provide examples to help a machine cluster the head of the distribution, then classify low-confidence examples in the tail. To accomplish this, Alloy introduces a modular cast and gather approach which leverages a machine learning backbone to stitch together different types of judgment tasks."}]}],data:{quirksMode:!1}},frontmatter:{date:"March 01, 2016",tags:["Crowdsourcing","Machine Learning"],title:"Alloy"},fields:{slug:"/research/alloy/",imgPath:{childImageSharp:{sizes:{base64:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAB5klEQVQoz2O4f//+t4sXL35//Pjx9x8/fnz/9u3b948fP34/e/bc97t3735/9erVZ6D4/7cvX7YwIAGz7C7rtorUwu3xyrYg/v+9SYxgiTt37/6/c+fO/5s3b4Lp169f///9+/f/58+fg/GjR4/+/ALyXz150gdUzmXhaO/sxMAgqVOzZHF5WtH/jTaaK8AGcTAwszExMzPcvHXr76+fP/8BDfn3E0r/+vXr3/////9BwS8g+//PX7/qQPrcPMLcvP20RZTqNi9Oy6r9v8TD+ICBiZF/iJyiOshChtt37v57/foNSA/IkP9///79DzT4PxL4jWQgV76Rvo03kNapXbKwLiXn/wZ7nc0Mnq1S/z1WMIFdeu/+g39Pnj4Deu/Fv+/fvwMN/AM36c+fPyD8G8qpZmBgU9bxjDHKMWbgVardsCI1p+H/CjfD7e6KojpB+irajsLiAgzPgAa9e//hP8ilQEP/f/z46f+zZ89A/kVx4fuXL8Fh6OrlIK/JwMBtWL9mQXV64f8lNho7GfyiXE3Dowx2MzAwMrS0tP7r7Oz+P336jH8zZs76P3nK1P8JCUn/Ozq6/m/YsPH/jh07f9+8eev/2TNnQV5mN/AOrrZTk7FRr988tyqv/v9uOzVwpPwHQhAAAMnOV/RmqAn/AAAAAElFTkSuQmCC",aspectRatio:2.8776978417266186,src:"/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-2fd78.png",srcSet:"/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-739b5.png 200w,\n/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-549e8.png 400w,\n/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-2fd78.png 800w,\n/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-c2444.png 1200w,\n/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-af555.png 1600w,\n/static/alloy-b641ae15ae2c808fa0b62a3c91fd134b-549f7.png 2000w",sizes:"(max-width: 800px) 100vw, 800px"}}}}}},pathContext:{slug:"/research/alloy/",prev:{excerpt:"Abstract Patients researching medical diagnoses, scientist exploring new fields of literature, and students learning about new domains are all faced with the challenge of capturing information they find for later use. However, saving information is…",html:'<h3 id="abstract"><a href="#abstract" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Abstract</h3>\n<p>Patients researching medical diagnoses, scientist exploring new fields of literature, and students learning about new domains are all faced with the challenge of capturing information they find for later use. However, saving information is challenging on mobile devices, where the small screen and font sizes combined with the inaccuracy of finger based touch screens makes it time consuming and stressful for people to select and save text for future use. Furthermore, beyond the challenge of simply selecting a region of bounded text on a mobile device, in many learning and data exploration tasks the boundaries of what text may be relevant and useful later are themselves uncertain for the user. In contrast to previous approaches which focused on speeding up the selection process by making the identification of hard boundaries faster, we introduce the idea of intentionally supporting uncertain input in the context of saving information during complex reading and information exploration. We embody this idea in a system that uses force touch and fuzzy bounding boxes along with posthoc expandable context to support identifying and saving information in an intentionally uncertain way on mobile devices. In a two part user study we find that this approach reduced selection time and was preferred by participants over the default system text selection method.</p>',id:"/Users/nhahn/Research/PersonalSite/src/pages/research/highlighting/index.md absPath of file >>> MarkdownRemark",timeToRead:1,frontmatter:{date:"2016-04-03T18:00:00.000Z",tags:["iOS","Interaction Techniques","Annotation"],title:"Intentionally Uncertain Input"},fields:{slug:"/research/highlighting/"}},next:{excerpt:"Abstract Crowdsourcing offers a powerful new paradigm for online work. However, real world tasks are often interdependent, requiring a big picture view of the difference pieces involved. Existing crowdsourcing approaches that support such tasks…",html:'<h3 id="abstract"><a href="#abstract" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Abstract</h3>\n<p>Crowdsourcing offers a powerful new paradigm for online work. However, real world tasks are often interdependent, requiring a big picture view of the difference pieces involved. Existing crowdsourcing approaches that support such tasks — ranging from Wikipedia to flash teams — are bottlenecked by relying on a small number of individuals to maintain the big picture. In this paper, we explore the idea that a computational system can scaffold an emerging interdependent, big picture view entirely through the small contributions of individuals, each of whom sees only a part of the whole. To investigate the viability, strengths, and weaknesses of this approach we instantiate the idea in a prototype system for accomplishing distributed information synthesis and evaluate its output across a variety of topics.  We also contribute a set of design patterns that may be informative for other systems aimed at supporting big picture thinking in small pieces.</p>\n<h3 id="appendix"><a href="#appendix" aria-hidden="true" class="anchor"><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Appendix</h3>\n<p>Below is a list of the KA responses to the questions listed in the paper:</p>\n<ul>\n<li><a href="https://turkwith.us/questions/102/answer/12" target="_blank" rel="nofollow noopener noreferrer">How do I unclog my bathtub drain?</a></li>\n<li><a href="https://turkwith.us/questions/115/answer/12" target="_blank" rel="nofollow noopener noreferrer">How do I get my tomato plants to produce more tomatoes?</a></li>\n<li><a href="https://turkwith.us/questions/153/answer/12" target="_blank" rel="nofollow noopener noreferrer">What are the best attractions in LA if I have two little kids?</a></li>\n<li><a href="https://turkwith.us/questions/116/answer/12" target="_blank" rel="nofollow noopener noreferrer">What are the best day trips possible from Barcelona, Spain?</a></li>\n<li><a href="https://turkwith.us/questions/177/answer/12" target="_blank" rel="nofollow noopener noreferrer">My Worcester CDi Boiler pressure is low. How can I fix it?</a></li>\n<li><a href="https://turkwith.us/questions/168/answer/12" target="_blank" rel="nofollow noopener noreferrer">2003 Dodge Durango has an OBD-II error code of P440. How do I fix it?</a></li>\n<li><a href="https://turkwith.us/questions/175/answer/12" target="_blank" rel="nofollow noopener noreferrer">2005 Chevy Silverado has an OBD-II error code of C0327. How do I fix it?</a></li>\n<li><a href="https://turkwith.us/questions/160/answer/12" target="_blank" rel="nofollow noopener noreferrer">How do I deal with the arthritis in my knee as a 28 year old?</a></li>\n<li><a href="https://turkwith.us/questions/161/answer/12" target="_blank" rel="nofollow noopener noreferrer">My Playstation 3 has a solid yellow light, how do I fix it?</a></li>\n<li><a href="https://turkwith.us/questions/162/answer/12" target="_blank" rel="nofollow noopener noreferrer">What are the key arguments for and against Global Warming?</a></li>\n<li><a href="https://turkwith.us/questions/163/answer/12" target="_blank" rel="nofollow noopener noreferrer">How do I use the VIM text editor?</a></li>\n</ul>',id:"/Users/nhahn/Research/PersonalSite/src/pages/research/ka/index.md absPath of file >>> MarkdownRemark",timeToRead:2,frontmatter:{date:"2015-12-30T16:29:56.000Z",tags:["Crowdsourcing","Sensemaking","Ruby on Rails"],title:"Knowledge Accelerator (KA)"},fields:{slug:"/research/ka/"}}}}}});
//# sourceMappingURL=path---research-alloy-f973ebc48693c3711af2.js.map